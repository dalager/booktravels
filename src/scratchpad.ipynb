{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load goodreads data\n",
    "Og lidt oprydning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\christian.dalager\\AppData\\Local\\Temp\\ipykernel_33328\\3162756380.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('Author').apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import main\n",
    "import pandas as pd\n",
    "# load goodreads data, clean whitespace from author names and filter out unread books\n",
    "df = main.read_data()\n",
    "df['Author'] = df['Author'].str.replace(r'\\s+', ' ', regex=True)\n",
    "df['Author'].unique()\n",
    "df=df[df['Read Count'] > 0]\n",
    "\n",
    "\n",
    "# collapse the list on author and add book count and average 'Average Rating'\n",
    "df = df.groupby('Author').apply(lambda x: pd.Series({\n",
    "    'Title': ', '.join(x['Title']),\n",
    "    'Average Rating': x['Average Rating'].mean(),\n",
    "})).reset_index()\n",
    "\n",
    "\n",
    "df['Books'] = df['Title'].str.split(', ')\n",
    "df.drop('Title', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author country lookup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion til at kalde wiki datas SPARQL endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# pip install sparqlwrapper\n",
    "# https://rdflib.github.io/sparqlwrapper/\n",
    "\n",
    "import sys\n",
    "import re\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "\n",
    "def execute_query(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s (christian@dalager.com)\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "def get_author_countries(author_name):\n",
    "    author_name = re.sub(r\"\\s+\", \" \", author_name)\n",
    "    author_name = author_name.strip()\n",
    "\n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "    query = (\n",
    "        \"\"\"SELECT ?countryLabel WHERE {\n",
    "        ?author ?label \"%s\"@en.\n",
    "        ?author wdt:P27 ?country.\n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "        }\"\"\"\n",
    "        % author_name\n",
    "    )\n",
    "\n",
    "    results = execute_query(endpoint_url, query)\n",
    "\n",
    "    bindings = results[\"results\"][\"bindings\"]\n",
    "    countries = list({entry[\"countryLabel\"][\"value\"] for entry in bindings})\n",
    "\n",
    "    return countries\n",
    "\n",
    "\n",
    "country = get_author_countries(\"Lars Kepler\")\n",
    "print(country)\n",
    "\n",
    "# country['countryLab']['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kald data apiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all author names from \"Author\" to a unique list\n",
    "import pandas as pd\n",
    "authors = df['Author'].unique()\n",
    "\n",
    "print(f'Requesting {len(authors)} authors')\n",
    "\n",
    "# Create a list to collect author and their countries\n",
    "author_country_list = []\n",
    "\n",
    "# Iterate over all authors and get the countries  (1.5 min)\n",
    "for author in authors:\n",
    "    countries = get_author_countries(author)  # Make sure this returns a list of countries\n",
    "    author_country_list.append({'Author': author, 'Countries': countries})\n",
    "\n",
    "df_authorcountries = pd.DataFrame(author_country_list)\n",
    "    \n",
    "# save to csv\n",
    "df_authorcountries.to_csv('../data/author_countries.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begynd at arbejde med listerne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authorcountries = pd.read_csv('../data/author_countries.csv')\n",
    "\n",
    "import ast\n",
    "# handle authors with no countries\n",
    "for index, row in df_authorcountries.iterrows():\n",
    "    countries = ast.literal_eval(row['Countries'])\n",
    "    df_authorcountries.at[index, 'Countries'] = countries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually located authors' countries in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_manually_placed = pd.read_csv('../data/manually_placed.csv')\n",
    "# import ast\n",
    "# # handle authors with no countries\n",
    "for index, row in df_manually_placed.iterrows():\n",
    "    countries = ast.literal_eval(row['Countries'])\n",
    "    df_manually_placed.at[index, 'Countries'] = countries\n",
    "\n",
    "df_manually_placed.rename(columns={'Countries': 'Countries_Manually_Placed'}, inplace=True)\n",
    "merged_df = pd.merge(df_authorcountries, df_manually_placed[['Author', 'Countries_Manually_Placed']], on='Author', how='left', validate='1:1')\n",
    "# Replace the 'Countries' column with the corrected countries where available\n",
    "merged_df['Countries'] = merged_df['Countries_Manually_Placed'].fillna(merged_df['Countries'])\n",
    "\n",
    "# Drop the 'Countries_Manually_Placed' column if you don't need it anymore\n",
    "merged_df=merged_df.drop(columns=['Countries_Manually_Placed'])\n",
    "\n",
    "df_authorcountries = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# read author countries\n",
    "#df_authorcountries = pd.read_csv('../data/author_countries.csv')\n",
    "#df_authorcountries\n",
    "\n",
    "df_final = pd.merge(df, df_authorcountries, on='Author', how='left', validate='1:1')\n",
    "\n",
    "\n",
    "df_final.to_csv('../data/myauthorlist_with_countries_and_books.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show me the countries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ancient Rome',\n",
       " 'Australia',\n",
       " 'Austria',\n",
       " 'Austria-Hungary',\n",
       " 'Brazil',\n",
       " 'Canada',\n",
       " 'Chile',\n",
       " 'Cisleithania',\n",
       " 'Classical Athens',\n",
       " 'Colombia',\n",
       " 'Czech Republic',\n",
       " 'Czechoslovakia',\n",
       " 'Denmark',\n",
       " 'Dutch Republic',\n",
       " 'England',\n",
       " 'Estonia',\n",
       " 'Ethiopia',\n",
       " 'Finland',\n",
       " 'France',\n",
       " 'German Empire',\n",
       " 'Germany',\n",
       " 'Greenland',\n",
       " 'Haiti',\n",
       " 'Hungary',\n",
       " 'India',\n",
       " 'Iran',\n",
       " 'Israel',\n",
       " 'Italy',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Kingdom of Denmark',\n",
       " 'Kingdom of England',\n",
       " 'Kingdom of Great Britain',\n",
       " 'Kingdom of Italy',\n",
       " 'Kingdom of Scotland',\n",
       " 'Kingdom of the Netherlands',\n",
       " 'Lebanon',\n",
       " 'Malaysia',\n",
       " 'Mexico',\n",
       " 'Nazi Germany',\n",
       " 'New Zealand',\n",
       " 'Nigeria',\n",
       " 'Northern Ireland',\n",
       " 'Norway',\n",
       " \"People's Republic of China\",\n",
       " 'Poland',\n",
       " 'Republic of Ireland',\n",
       " 'Russia',\n",
       " 'Russian Empire',\n",
       " 'Russian Socialist Federative Soviet Republic',\n",
       " 'Russian Soviet Federative Socialist Republic',\n",
       " 'Scotland',\n",
       " 'Senegal',\n",
       " 'Somalia',\n",
       " 'South Africa',\n",
       " 'Spain',\n",
       " 'Sweden',\n",
       " 'Switzerland',\n",
       " 'United Kingdom',\n",
       " 'United Kingdom of Great Britain and Ireland',\n",
       " 'United States of America',\n",
       " 'Vietnam',\n",
       " 'Wales',\n",
       " 'Weimar Republic',\n",
       " 'http://www.wikidata.org/.well-known/genid/62a0c626d05426b8941a3bca5e0211d6',\n",
       " 'statelessness']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of uniqe countries\n",
    "\n",
    "\n",
    "\n",
    "cs=list(df_final['Countries'])\n",
    "cs = {item for sublist in cs for item in sublist}\n",
    "\n",
    "cs = list(cs)\n",
    "\n",
    "cs.sort()\n",
    "cs\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
