{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load goodreads data\n",
    "Og lidt oprydning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "import pandas as pd\n",
    "\n",
    "# load goodreads data, clean whitespace from author names and filter out unread books\n",
    "df = main.read_data()\n",
    "df['Author'] = df['Author'].str.replace(r'\\s+', ' ', regex=True)\n",
    "df['Author'].unique()\n",
    "df=df[df['Read Count'] > 0]\n",
    "\n",
    "# collapse the list on author and add book count and average 'Average Rating'\n",
    "df = df.groupby('Author').apply(lambda x: pd.Series({\n",
    "    'Title': ', '.join(x['Title']),\n",
    "    'Average Rating': x['Average Rating'].mean(),\n",
    "})).reset_index()\n",
    "\n",
    "df['Books'] = df['Title'].str.split(', ')\n",
    "df.drop('Title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author country lookup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion til at kalde wiki datas SPARQL endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "def execute_query(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s (christian@dalager.com)\" % (\n",
    "        sys.version_info[0],\n",
    "        sys.version_info[1],\n",
    "    )\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "def get_author_countries(author_name):\n",
    "    author_name = re.sub(r\"\\s+\", \" \", author_name)\n",
    "    author_name = author_name.strip()\n",
    "\n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "    query = (\n",
    "        \"\"\"SELECT ?countryLabel WHERE {\n",
    "        ?author ?label \"%s\"@en.\n",
    "        ?author wdt:P27 ?country.\n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "        }\"\"\"\n",
    "        % author_name\n",
    "    )\n",
    "\n",
    "    results = execute_query(endpoint_url, query)\n",
    "\n",
    "    bindings = results[\"results\"][\"bindings\"]\n",
    "    countries = list({entry[\"countryLabel\"][\"value\"] for entry in bindings})\n",
    "\n",
    "    return countries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kald data apiet\n",
    "Det tager 1-2 minutter at lave 369 opslag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all author names from \"Author\" to a unique list\n",
    "import pandas as pd\n",
    "authors = df['Author'].unique()\n",
    "\n",
    "print(f'Requesting {len(authors)} authors')\n",
    "\n",
    "# Create a list to collect author and their countries\n",
    "author_country_list = []\n",
    "\n",
    "# Iterate over all authors and get the countries  (1.5 min)\n",
    "for author in authors:\n",
    "    countries = get_author_countries(author)  # Make sure this returns a list of countries\n",
    "    author_country_list.append({'Author': author, 'Countries': countries})\n",
    "\n",
    "df_authorcountries = pd.DataFrame(author_country_list)\n",
    "    \n",
    "# save to csv\n",
    "df_authorcountries.to_csv('../data/author_countries.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begynd at arbejde med listerne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authorcountries = pd.read_csv('../data/author_countries.csv')\n",
    "\n",
    "import ast\n",
    "for index, row in df_authorcountries.iterrows():\n",
    "    countries = ast.literal_eval(row['Countries'])\n",
    "    df_authorcountries.at[index, 'Countries'] = countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually located authors' countries in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manually_placed = pd.read_csv('../data/manually_placed.csv')\n",
    "\n",
    "for index, row in df_manually_placed.iterrows():\n",
    "    countries = ast.literal_eval(row['Countries'])\n",
    "    df_manually_placed.at[index, 'Countries'] = countries\n",
    "\n",
    "df_manually_placed.rename(columns={'Countries': 'Countries_Manually_Placed'}, inplace=True)\n",
    "merged_df = pd.merge(df_authorcountries, df_manually_placed[['Author', 'Countries_Manually_Placed']], on='Author', how='left', validate='1:1')\n",
    "# Replace the 'Countries' column with the corrected countries where available\n",
    "merged_df['Countries'] = merged_df['Countries_Manually_Placed'].fillna(merged_df['Countries'])\n",
    "\n",
    "# Drop the 'Countries_Manually_Placed' column if you don't need it anymore\n",
    "merged_df=merged_df.drop(columns=['Countries_Manually_Placed'])\n",
    "\n",
    "df_authorcountries = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df, df_authorcountries, on='Author', how='left', validate='1:1')\n",
    "df_final.to_csv('../data/myauthorlist_with_countries_and_books.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show me the countries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of uniqe countries\n",
    "cs=list(df_final['Countries'])\n",
    "cs = {item for sublist in cs for item in sublist}\n",
    "cs = list(cs)\n",
    "cs.sort()\n",
    "cs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
